{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(-10, 10, (128,3)).float()\n",
    "y = (x[:,0]*(np.cos(x[:,1]) + np.exp(x[:,1]/3)) + x[:,2]) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "data = [(xi,yi) for xi,yi in zip(x, y)]\n",
    "loader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3., -1.,  0.],\n",
      "        [ 4., -6.,  8.],\n",
      "        [-2.,  5.,  4.],\n",
      "        [ 0., -5.,  6.]])\n",
      "tensor([ 0.38,  1.24, -0.72,  0.60])\n"
     ]
    }
   ],
   "source": [
    "for x,y in loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(3,2)\n",
    "        self.fc2 = nn.Linear(2,2)\n",
    "        self.fc3 = nn.Linear(2,1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1.register_forward_hook(self._forward_hook)\n",
    "        self.fc1.register_full_backward_hook(self._backward_hook)\n",
    "        self.fc2.register_forward_hook(self._forward_hook)\n",
    "        self.fc2.register_full_backward_hook(self._backward_hook)\n",
    "        self.fc3.register_forward_hook(self._forward_hook)\n",
    "        self.fc3.register_full_backward_hook(self._backward_hook)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.fc1(x)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu(y)\n",
    "        return self.fc3(y)\n",
    "\n",
    "    def _forward_hook(self, module, inp, output):\n",
    "        print(type(inp))\n",
    "        print(len(inp))\n",
    "        print(type(output))\n",
    "        print(inp)\n",
    "        print(output)\n",
    "        print()\n",
    "\n",
    "    def _backward_hook(self, module, grad_input, grad_output):\n",
    "        print(type(grad_output))\n",
    "        print(len(grad_output))\n",
    "        print(type(grad_input))\n",
    "        print(len(grad_input))\n",
    "        print(grad_output)\n",
    "        print(grad_input)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3., -1.,  0.],\n",
       "        [ 4., -6.,  8.],\n",
       "        [-2.,  5.,  4.],\n",
       "        [ 0., -5.,  6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "1\n",
      "<class 'torch.Tensor'>\n",
      "(tensor([[ 3., -1.,  0.],\n",
      "        [ 4., -6.,  8.],\n",
      "        [-2.,  5.,  4.],\n",
      "        [ 0., -5.,  6.]]),)\n",
      "tensor([[-0.10,  1.31],\n",
      "        [-0.57, -1.47],\n",
      "        [ 0.74, -0.91],\n",
      "        [-0.37, -2.63]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "<class 'tuple'>\n",
      "1\n",
      "<class 'torch.Tensor'>\n",
      "(tensor([[0.00, 1.31],\n",
      "        [0.00, 0.00],\n",
      "        [0.74, 0.00],\n",
      "        [0.00, 0.00]], grad_fn=<BackwardHookFunctionBackward>),)\n",
      "tensor([[-0.63, -0.48],\n",
      "        [-0.69,  0.43],\n",
      "        [-0.44,  0.46],\n",
      "        [-0.69,  0.43]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "<class 'tuple'>\n",
      "1\n",
      "<class 'torch.Tensor'>\n",
      "(tensor([[0.00, 0.00],\n",
      "        [0.00, 0.43],\n",
      "        [0.00, 0.46],\n",
      "        [0.00, 0.43]], grad_fn=<BackwardHookFunctionBackward>),)\n",
      "tensor([[-0.29],\n",
      "        [-0.01],\n",
      "        [ 0.00],\n",
      "        [-0.01]], grad_fn=<AddmmBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.29, -0.01,  0.00, -0.01], grad_fn=<SqueezeBackward0>),\n",
       " tensor([ 0.38,  1.24, -0.72,  0.60]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.squeeze(), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.73, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((y - y_hat.squeeze())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.73, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "loss = mse(y_hat, y.unsqueeze(1))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "1\n",
      "<class 'tuple'>\n",
      "1\n",
      "(tensor([[-0.33],\n",
      "        [-0.63],\n",
      "        [ 0.36],\n",
      "        [-0.31]]),)\n",
      "(tensor([[-0.23, -0.22],\n",
      "        [-0.43, -0.41],\n",
      "        [ 0.25,  0.23],\n",
      "        [-0.21, -0.20]]),)\n",
      "\n",
      "<class 'tuple'>\n",
      "1\n",
      "<class 'tuple'>\n",
      "1\n",
      "(tensor([[ 0.00,  0.00],\n",
      "        [ 0.00, -0.41],\n",
      "        [ 0.00,  0.23],\n",
      "        [ 0.00, -0.20]]),)\n",
      "(tensor([[ 0.00,  0.00],\n",
      "        [-0.02,  0.28],\n",
      "        [ 0.01, -0.16],\n",
      "        [-0.01,  0.14]]),)\n",
      "\n",
      "<class 'tuple'>\n",
      "1\n",
      "<class 'tuple'>\n",
      "1\n",
      "(tensor([[0.00, 0.00],\n",
      "        [0.00, 0.00],\n",
      "        [0.01, 0.00],\n",
      "        [0.00, 0.00]]),)\n",
      "(None,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.03,  0.11,  0.01],\n",
       "         [ 0.48,  0.21, -0.27]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.34,  0.05],\n",
       "         [ 0.04, -0.69]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.68, 0.65]], requires_grad=True))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight, model.fc2.weight, model.fc3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.02,  0.04,  0.03],\n",
       "         [ 0.00,  0.00,  0.00]]),\n",
       " tensor([[0.00, 0.00],\n",
       "         [0.17, 0.00]]),\n",
       " tensor([[ 0.00, -0.24]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.grad, model.fc2.weight.grad, model.fc3.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.19,  1.23],\n",
       "        [-0.67, -1.55],\n",
       "        [ 0.64, -0.99],\n",
       "        [-0.46, -2.71]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x, model.fc1.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.10,  1.31],\n",
       "        [-0.57, -1.47],\n",
       "        [ 0.74, -0.91],\n",
       "        [-0.37, -2.63]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = torch.matmul(x, model.fc1.weight.T) + model.fc1.bias\n",
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R1 = torch.ones_like(z1)\n",
    "R1[z1<0] = 0\n",
    "R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.00, 1.31],\n",
       "        [0.00, 0.00],\n",
       "        [0.74, 0.00],\n",
       "        [0.00, 0.00]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = F.relu(z1)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.06, -0.91],\n",
       "        [ 0.00,  0.00],\n",
       "        [ 0.25,  0.03],\n",
       "        [ 0.00,  0.00]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a1, model.fc2.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.63, -0.48],\n",
       "        [-0.69,  0.43],\n",
       "        [-0.44,  0.46],\n",
       "        [-0.69,  0.43]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2 = torch.matmul(a1, model.fc2.weight.T) + model.fc2.bias\n",
    "z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2 = torch.ones_like(z2)\n",
    "R2[z2<0] = 0\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.00, 0.00],\n",
       "        [0.00, 0.43],\n",
       "        [0.00, 0.46],\n",
       "        [0.00, 0.43]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = F.relu(z2)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.29],\n",
       "        [-0.01],\n",
       "        [ 0.00],\n",
       "        [-0.01]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3 = torch.matmul(a2, model.fc3.weight.T) + model.fc3.bias\n",
    "z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.33],\n",
       "        [-0.63],\n",
       "        [ 0.36],\n",
       "        [-0.31]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 2 / batch_size\n",
    "d3 = (z3 - y.unsqueeze(1))*c\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.00, -0.24], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d3*a2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.23, -0.22],\n",
       "        [-0.43, -0.41],\n",
       "        [ 0.25,  0.23],\n",
       "        [-0.21, -0.20]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(d3, model.fc3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.00, -0.00],\n",
       "        [-0.00, -0.41],\n",
       "        [ 0.00,  0.23],\n",
       "        [-0.00, -0.20]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = torch.matmul(d3, model.fc3.weight)*R2\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.00, 0.00],\n",
       "        [0.17, 0.00]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(d2.T, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.00,  0.00],\n",
       "        [-0.02,  0.28],\n",
       "        [ 0.01, -0.16],\n",
       "        [-0.01,  0.14]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(d2, model.fc2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.00, 0.00],\n",
       "        [-0.00, 0.00],\n",
       "        [0.01, -0.00],\n",
       "        [-0.00, 0.00]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = torch.matmul(d2, model.fc2.weight)*R1\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.02,  0.04,  0.03],\n",
       "        [ 0.00,  0.00,  0.00]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(d1.T, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstraction Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 128\n",
    "d_in = 512\n",
    "d_out = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.random.rand(b,d_in)\n",
    "W = np.random.rand(d_in,d_in/2)\n",
    "R = np.random.randint(2, size=(b, d_in/2))\n",
    "W2 = np.random.rand(d_in/2, d_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gp = G@W*R@W2\n",
    "Gp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1786.1721, 1955.2175, 1816.2568, ..., 1796.5105, 1894.5028,\n",
       "        1978.8702],\n",
       "       [1842.8868, 2095.1533, 2065.6891, ..., 2150.0277, 2133.2831,\n",
       "        2143.3209],\n",
       "       [1852.1479, 2166.2636, 2067.5268, ..., 1956.8618, 2020.4607,\n",
       "        1997.3477],\n",
       "       ...,\n",
       "       [1709.8471, 1959.5511, 1865.9934, ..., 1833.1756, 1798.5266,\n",
       "        2060.535 ],\n",
       "       [1770.6676, 1794.436 , 1751.9749, ..., 1741.3164, 1972.1624,\n",
       "        1878.5704],\n",
       "       [2089.3307, 2368.257 , 2154.0787, ..., 2414.3493, 2346.2531,\n",
       "        2413.0108]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = 1e-9\n",
    "#M1 = np.linalg.inv(G.T@G+delta*np.eye(d))@G.T@Gp\n",
    "M2 = np.linalg.solve(G.T@G+delta*np.eye(d_in), G.T@Gp)\n",
    "#G@M1\n",
    "G@M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006558552686109813"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.linalg.norm(Gp - G@M1)\n",
    "np.linalg.norm(Gp - G@M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -561.48  ,  -754.9675,  -544.6181, ...,  -784.4288, -1207.049 ,\n",
       "         -626.1764],\n",
       "       [ -424.4914,  -278.2212,  -267.1357, ...,  -394.6129,  -376.3098,\n",
       "         -437.4163],\n",
       "       [ -929.9578, -1709.0888,  -981.3751, ..., -1082.0538, -1363.0619,\n",
       "        -1410.1297],\n",
       "       ...,\n",
       "       [ -481.8205, -1032.0656,  -562.0955, ...,  -460.2439,  -335.0367,\n",
       "         -814.9755],\n",
       "       [ -854.3841,  -892.7037,  -608.2119, ...,  -956.6669, -1291.7438,\n",
       "         -970.9711],\n",
       "       [-1417.286 , -1943.2019, -1398.9774, ..., -1743.5616, -2019.2089,\n",
       "        -1928.0901]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2465, 0.1876, 0.0378, ..., 0.3044, 0.0731, 0.4655],\n",
       "       [0.3083, 0.3683, 0.0309, ..., 0.2417, 0.1843, 0.3492],\n",
       "       [0.2663, 0.1967, 0.3579, ..., 0.4696, 0.4908, 0.4162],\n",
       "       ...,\n",
       "       [0.3628, 0.1362, 0.1674, ..., 0.342 , 0.5531, 0.3067],\n",
       "       [0.2082, 0.3143, 0.2691, ..., 0.3634, 0.2865, 0.3306],\n",
       "       [0.3245, 0.5116, 0.2695, ..., 0.3301, 0.3837, 0.3764]])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 * R.mean(axis=0).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3 = W@(W2 * R.mean(axis=0).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.409 , 32.1285, 29.8569, ..., 30.78  , 32.1528, 31.7196],\n",
       "       [31.5173, 34.1343, 31.9446, ..., 34.0527, 33.7582, 33.29  ],\n",
       "       [29.2228, 32.6438, 31.1576, ..., 32.001 , 33.1844, 32.7538],\n",
       "       ...,\n",
       "       [31.3355, 33.8502, 30.1046, ..., 33.1273, 32.0806, 33.9928],\n",
       "       [29.3544, 34.0876, 31.9171, ..., 33.363 , 32.4551, 33.4492],\n",
       "       [29.7985, 33.897 , 31.4695, ..., 33.0704, 33.4874, 33.2684]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19416.35243953515"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(Gp - G@M3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (128,128) (128,256) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-339-26c950b63a68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (128,128) (128,256) "
     ]
    }
   ],
   "source": [
    "np.linalg.norm(Gp - G@W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.2206, 7.4171, 9.3154, ..., 7.6118, 7.7293, 5.8584],\n",
       "       [9.3547, 8.2342, 9.0923, ..., 7.273 , 9.2764, 6.5277],\n",
       "       [8.353 , 6.6033, 6.2257, ..., 7.5358, 7.1936, 6.3307],\n",
       "       ...,\n",
       "       [8.7655, 7.0064, 7.0619, ..., 4.5887, 6.3798, 6.6948],\n",
       "       [6.3136, 5.1219, 5.7426, ..., 4.7886, 5.4348, 4.5458],\n",
       "       [8.7906, 7.8088, 8.469 , ..., 6.3153, 6.6372, 6.1693]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G@M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.0282,  8.553 ,  9.6917, ...,  7.834 ,  9.0316,  8.1951],\n",
       "       [ 8.8574,  7.7185,  8.357 , ...,  6.3843,  7.5922,  6.9048],\n",
       "       [ 8.5076,  7.5449,  7.9306, ...,  6.8513,  7.7407,  7.0388],\n",
       "       ...,\n",
       "       [10.4831,  9.7266,  9.741 , ...,  7.6903,  8.9856,  8.9292],\n",
       "       [ 8.5683,  7.8353,  7.2812, ...,  5.9574,  7.7971,  6.8838],\n",
       "       [ 8.5757,  7.2657,  7.9985, ...,  6.6236,  7.4361,  6.8287]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G@M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4923, 4.8916, 4.1447, ..., 4.3604, 4.5179, 4.3836],\n",
       "       [3.9708, 2.8232, 5.5823, ..., 3.8476, 3.7759, 4.7226],\n",
       "       [4.63  , 3.42  , 5.058 , ..., 5.2431, 4.5323, 4.9604],\n",
       "       ...,\n",
       "       [4.3227, 3.2854, 4.2373, ..., 3.9835, 4.8602, 4.214 ],\n",
       "       [4.6283, 3.7563, 4.3044, ..., 4.1336, 3.571 , 3.5449],\n",
       "       [3.0164, 3.2921, 4.9042, ..., 3.172 , 4.2198, 4.4461]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[1, 1], [-1, -1]])\n",
    "X = np.array([[1, 2],[-1, 2], [2, -1], [1, -2]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  1],\n",
       "        [-1, -1]]),\n",
       " array([[ 1, -1,  2,  1],\n",
       "        [ 2,  2, -1, -2]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2, 1],\n",
       "       [2, 2, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RX = copy.deepcopy(X)\n",
    "RX[X<0] = 0\n",
    "RX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  2,  2,  1],\n",
       "       [-3, -2, -2, -1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = W@RX\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Y@X.T@np.linalg.inv(X@X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36,  0.88],\n",
       "       [-1.36, -0.88]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0199337741082997"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(M@X-Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.12,  0.4 ,  1.84, -0.4 ],\n",
       "        [-3.12, -0.4 , -1.84,  0.4 ]]),\n",
       " array([[ 3,  2,  2,  1],\n",
       "        [-3, -2, -2, -1]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M@X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
